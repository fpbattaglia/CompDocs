{
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Parallel work on the cluster with IPython Notebook\n",
      "==================================================\n",
      "\n",
      "Here we will see how to use IPython notebook to parallelize your work\n",
      "This notebook is meant to be run on patron. \n",
      "\n",
      "Configuring IPython for Cluster work\n",
      "------------------------------------\n",
      "\n",
      "IPython handles cluster work in a fairly automated way. But first you need to take care of some configuration. \n",
      "The procedure here is adapted from (http://ipython.org/ipython-doc/stable/parallel/parallel_intro.html)\n",
      "and from http://ipython.org/ipython-doc/stable/parallel/parallel_process.html). \n",
      "From patron, you need to run \n",
      "> ipython profile create --parallel --profile=sge\n",
      "\n",
      "this will create, in your home directory, the directory ~/.ipython/profile_pbs\n",
      "\n",
      "In this directory, you need to make some changes. \n",
      "You can do that by overwriting the files ipcontroller_config.py and ipcluster_config.py with the version in this repo.\n",
      "\n",
      "In terms of configuration you are all set. You need to go through this step only once. \n",
      "\n",
      "\n",
      "Starting Python Notebook\n",
      "------------------------\n",
      "\n",
      "Still from patron, start the notebook server with \n",
      "> ipython notebook --no-browser --port=62000\n",
      "\n",
      "The 62000 is a high range port chosen so that it doesn't upset the security settings of the cluster and the science firewall\n",
      "\n",
      "you can then connect (from the Science network, or Science VPN) from your browser, by pointing it to \n",
      "> http://patron.science.ru.nl:62000\n",
      "\n",
      "The Home window of IPython notebook will show up. Got to the \"clusters\" tab. \n",
      "You should see two profiles, \"default\" and \"pbs\". From \"pbs\" choose the number of hosts you want to have (how many CPUs you want to use in parallel), e.g. 8 or 16. Click \"Start\". The cluster should be ready\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Parallel code in a notebook\n",
      "---------------------------\n",
      "\n",
      "Here you prepare the itnerface to the cluster, the Client object defined below"
     ]
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "from IPython.parallel import Client\n",
      "c = Client(profile='pbs')"
     ],
     "language": "python",
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now let's define some relatively lengthy calculation"
     ]
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "def some_calculations():\n",
      "    import numpy as np\n",
      "    a = np.random.uniform(size=[1000,1000])\n",
      "    for i in range(500):\n",
      "        b = np.dot(a,a)\n",
      "    return b"
     ],
     "language": "python",
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's see how long it takes. This runs on the frontend node "
     ]
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 1min 6s per loop\n"
       ]
      }
     ],
     "input": [
      "%timeit some_calculations()"
     ],
     "language": "python",
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now for the cool part. The instruction below (%timeit is just to compute the execution time) runs the same code 8 times in parallel, on 8 compute nodes. You can see that it is much faster, even though it's doing 8 times as much work!"
     ]
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 21.1 s per loop\n"
       ]
      }
     ],
     "input": [
      "%timeit c[:].apply_sync(some_calculations)"
     ],
     "language": "python",
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Of course, you don't have to repeat the same code on all the compute node, which is pointless... "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we create a view to our cluster"
     ]
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "dview = c[:]"
     ],
     "language": "python",
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "<DirectView [0, 1, 2, 3,...]>"
       ],
       "metadata": {}
      }
     ],
     "input": [
      "dview"
     ],
     "language": "python",
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "import numpy as np"
     ],
     "language": "python",
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's make a function that take an argument"
     ]
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "def some_other_calculations(e):\n",
      "    import numpy as np\n",
      "    return np.sqrt(e)"
     ],
     "language": "python",
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "with map_sync you call the function on a different node, each time with a different argument from the list given as second argument"
     ]
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "[1.0,\n",
        " 1.4142135623730951,\n",
        " 1.7320508075688772,\n",
        " 2.0,\n",
        " 2.2360679774997898,\n",
        " 2.4494897427831779,\n",
        " 2.6457513110645907,\n",
        " 2.8284271247461903]"
       ],
       "metadata": {}
      }
     ],
     "input": [
      "dview.map_sync(some_other_calculations, np.arange(1,9))"
     ],
     "language": "python",
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You could give as second argument for example a list of sessions, and you would have them all done in parallel (or at least 8 of them in this case). This is called the \"direct\" cluster interface, where you control each node explicitly. Other interfaces may allow you more flexibility, and for example balance the load between nodes if some jobs are  shorter than other. We'll get to that in another notebook.\n",
      "\n",
      "A typical workflow may imply setting up and debug your analysis on one session interactively, e.g. on your computer, then move the notebook to the cluster and run it on the rest of the data with this mechanism."
     ]
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    }
   ]
  }
 ],
 "cells": [],
 "metadata": {
  "name": "",
  "signature": "sha256:4b201d9a0db0a72ea81ba775bc12597a9e4d9857f63d26105381ba6799675cda"
 },
 "nbformat": 3,
 "nbformat_minor": 0
}